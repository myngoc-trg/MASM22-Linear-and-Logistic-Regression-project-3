---
title: "project2"
author: "Nancy Truong"
date: "2025-04-15"
output: html_document
---
# 1. Low plasma β-carotene and vitamin use
## (a)
```{r}
library(tidyverse); theme_set(theme_bw() + theme(text = element_text(size = 18)))
getwd()  # Check current working directory
list.files("Data")  # Check if 'carotene.xlsx' is inside the "Data" folder
install.packages("readxl")  # Only run once if not installed
library(readxl)
library(dplyr)  # Load dplyr for select()
# Lecture 3 - Elasticity - multiple linear regression
library(caret)
library(pROC)
library(car)
library(rstatix)
library(GGally)
df <- read_excel("MASM22/Data/carotene.xlsx")
head(df)
class(df)
```
0.42 μmol/l (micromoles per litre)
= ? ng/ml  (nanograms per millilitre)

β-carotene: C40H56
```{r}
plasmab_molar_mass <- 40*12.010788+56*1.0079477
alpha <- 0.42*plasmab_molar_mass
# 225.4882
summary(df)
# 3rd Qu.: 230.0  
```

## (b)
Create a new variable, lowplasma_01, that is 1 when betaplasma < a ng/ml, and 0 otherwise.

```{r}
#?ifelse
#plasmab$lowplasma_01 <- ifelse(plasmab$betaplasma < alpha, 1, 0)
glimpse(df)

df |> mutate(
lowplasma_01 = as.numeric(betaplasma < alpha),
lowplasma_hl = factor(lowplasma_01,
levels = c(0, 1),
labels = c("high", "low"))) -> df
```
You can then plot with, e.g., aes(..., y = lowplasma_01) and get 0/1 on the y-axis, while using aes(..., color = lowplasma_hl) to get separate colours for the high and
low categories.
```{r}
glimpse(df)
ggplot(df, aes(age, lowplasma_01, color = lowplasma_hl)) +
  geom_point() +
  #geom_smooth() +
  xlab("") +
  ylab("Low concentration of plasma β-carotene") +
  labs(title = "Low plasma β-carotene(=1) or Not low β-carotene (=0) vs x",
       color = "Beta-carotene") 
```
In the report, present the number of observations that have "low" and "high" plasma β-carotene concentrations, respectively, together with the proportion with "low" concentration, as a percentage.
```{r}
lowplasma <- as.data.frame(
  count(df, lowplasma_01))
lowplasma$percentage <- round(lowplasma$n*100/sum(lowplasma$n),1)
lowplasma
```


## (c)
Start by examining the relationship between low plasma β-carotene and vitamin use by counting the number of observations for all combinations, using count, and then transform the result into a wide format with pivot_wider(), resulting in a 3 × 2-table
```{r}
plasma_vituse <- df |> count(vituse, lowplasma_hl) |>
pivot_wider(id_cols = vituse,
names_from = lowplasma_hl,
values_from = n)
plasma_vituse
```


Calculate the probabilities and the corresponding odds for having low plasma β-carotene for each of the three vitamin use categories, and add them to the table (mutate()).
```{r}
plasma_vituse
# Prob. for having low plasma B
# Correspnding odds
# odds = Pr(success) / Pr(failure)
plasma_vituse <- plasma_vituse |>
  mutate(
    prob_low = low*100/(low + high),
    odds = prob_low / (100-prob_low)
  )
plasma_vituse
```
Also calculate the odds ratios for each of the categories, compared to a suitable reference category,
and add them to the table, Table.1(c).

```{r}
mutate(df,
       vituse = factor(vituse,
                         levels = c(1, 2, 3),
                         labels = c("often", "notoften", "no"))) -> df
# odd ratios = OR = oddsj/ odd ref
glimpse(df)

plasma_vituse <- plasma_vituse |>
  mutate(
   OR = odds / plasma_vituse$odds[1]
  )
plasma_vituse



```

## (d)
Fit a logistic regression model, Model.1(d), for lowplasma_01 or lowplasma_hl with vituse as explanatory variable.

Present the β-estimates, the e^β -estimates and their profile likelihood based 95 % confidence intervals.
-The confint()-function calculates profile likelihood based confidence intervals for the parameters.
```{r}
vituse_glm <- glm(lowplasma_01 ~ vituse, family = "binomial", data = df)
vituse_glm
vituse_sum <- summary(vituse_glm)
vituse_sum
vituse_sum$coefficients
bhat <- vituse_glm$coefficients
ci.beta <- confint(vituse_glm)
or = exp(bhat)
ci.or <- exp(ci.beta)
cbind('beta'=bhat,ci.beta, `exp(beta)` = or, ci.or) |> round(digits = 2)
```
Identify these estimates with the corresponding
values in Table.1(c), and express the odds and the probabilities for each of the categories as functions of the β-parameters
odds of often = e^(beta_0)
odds of notoften = e^(beta_0 + beta_1)
odds of no = e^(beta_0 + beta_2)

p_i (low plasma probability) = e^x_iB / 1 + e^x_iB

Use the regression model to calculate the linear predictor, the odds, and the probability of having a low plasma β-carotene concentration, together with their respective 95 % confidence intervals, for each of the three vitamin use categories. 
Compare the result with the
probabilities in Table.1(c)
```{r}
vituse_x0 <- data.frame(vituse = c("often", "notoften", "no"))

vituse_pred <- predict(vituse_glm, vituse_x0, se.fit = TRUE)
vituse_pred
lambda <- qnorm(1 - 0.05/2)

vituse_x0 |> mutate(
  logit = vituse_pred$fit,
  logit.lwr = vituse_pred$fit - lambda*vituse_pred$se.fit,
  logit.upr = vituse_pred$fit + lambda*vituse_pred$se.fit,
  
  "odds" = exp(vituse_pred$fit),
  odds.lwr = exp(logit.lwr),
  odds.upr = exp(logit.upr),
  
  "prob_low" = exp(vituse_pred$fit)/ (1+exp(vituse_pred$fit)),
  p.lwr = odds.lwr/(1 + odds.lwr),
  p.upr = odds.upr/(1 + odds.upr)) -> vituse_x0

vituse_x0
```

## (e)
For Model.1(d), use a suitable test to determine whether there are any significant differences between the vitamin use categories in the model.

Report what type of test you use, the null hypothesis H0, the test statistic, the asymptotic distribution of the test statistic when H0 is true, the P-value and the conclusion.
H_0 : B1=B2=0
LR-test againsts the null model
calculating D_0 - D and the difference in the number of parameters, i.e., the difference in the degrees of freedom. Calculate the P-value using the Chi-squared distribution

```{r}
D_diff <- vituse_sum$null.deviance - vituse_sum$deviance
df_diff <- vituse_sum$df.null - vituse_sum$df.residual
chi2_alpha <- qchisq(p = 1 - 0.05, df = df_diff)
Pvalue <- pchisq(q = D_diff, df = df_diff, lower.tail = FALSE)

cbind(D_diff, df_diff, chi2_alpha, Pvalue)
```
p-value = 1.811218e-05
Reject H_0, all parameters seem to be significant

# 2 Low plasma β-carotene and BMI
We will now instead examin how the probability of having a low plasma β-carotene depends on BMI using a simple logistic regression.
## 2(a)
Plot lowplasma_01 against bmi and add a moving average.
```{r}
highlightcolors <- c("|d|>2" = "red", "v > 0.045" = "pink", "Cook's D>0.1" = "purple")
ggplot(df, aes(bmi, lowplasma_01)) +
  geom_point() +
  geom_smooth() +
  xlab("BMI (kg/m²)") +
  ylab("Low betaplasma") +
  labs(title = "Low betaplasma (=1) or Not low betaplasma (=0) vs BMI") +
  theme(
    plot.title = element_text(size = 10),        # Title size
    axis.title.x = element_text(size = 9),       # X-axis label size
    axis.title.y = element_text(size = 9),       # Y-axis label size
    axis.text.x = element_text(size = 8),        # X-axis tick values
    axis.text.y = element_text(size = 8)         # Y-axis tick values
  )
```
Does the probability of having low plasma beta-carotene increase or decrease with BMI? 
- BMI 20-35: prob of low betaplasma increases
- BMI>35: prob slightly decreases, larger uncertainty? grey band bigger?

Does this agree with what you found in Project 1?
generally yes

Fit a logistic regression for lowplasma_01 (or lowplasma_hl) as a function of BMI. This will be referred to as Model.2(a).

Present the β-estimates, the e^β estimates and their profile
likelihood based 95 % confidence intervals.

```{r}
bmi_glm <- glm(lowplasma_01 ~ bmi, family = "binomial", data = df)
bmi_glm
bmi_sum <- summary(bmi_glm)
bmi_sum

bmi_sum$coefficients
bhat <- bmi_glm$coefficients
ci.beta <- confint(bmi_glm)
or = exp(bhat)
ci.or <- exp(ci.beta)
cbind('beta'=bhat,ci.beta, `exp(beta)` = or, ci.or) |> round(digits = 2)
```

Add the predicted probabilities, and a 95 % confidence interval, to the plot and comment on the result.

```{r}
head(df)

df |> mutate(phat = predict(bmi_glm, type = "response")) -> bmi_pred
bmi_pred <- cbind(
  bmi_pred,
  logit = predict(bmi_glm, se.fit = TRUE))
glimpse(bmi_pred)
bmi_pred |> mutate(logit.residual.scale = NULL) -> bmi_pred

lambda <- qnorm(1 - 0.05/2)
bmi_pred |> mutate(
  logit.lwr = logit.fit - lambda*logit.se.fit,
  logit.upr = logit.fit + lambda*logit.se.fit,
  
  odds.lwr = exp(logit.lwr),
  odds.upr = exp(logit.upr),
  
  p.lwr = odds.lwr/(1 + odds.lwr),
  p.upr = odds.upr/(1 + odds.upr)) -> bmi_pred
glimpse(bmi_pred)

ggplot(bmi_pred, aes(bmi, lowplasma_01)) +
  geom_point() +
  geom_smooth(se = FALSE, linetype = "dashed") +
  geom_line(aes(y = phat), color = "red", size = 1) +
  geom_ribbon(aes(ymin = p.lwr, ymax = p.upr), alpha = 0.2) +
  xlab("BMI (kg/m²)") +
  ylab("Low betaplasma") +
  labs(title = "Low betaplasma (=1) or Not low betaplasma (=0) vs BMI",
       caption = "red = fitted line, with 95% confidence interval, 
       blue dashed = moving average") +
  theme(
    plot.title = element_text(size = 10),        # Title size
    axis.title.x = element_text(size = 9),       # X-axis label size
    axis.title.y = element_text(size = 9),       # Y-axis label size
    axis.text.x = element_text(size = 8),        # X-axis tick values
    axis.text.y = element_text(size = 8),         # Y-axis tick values,        # Y-axis tick values
    plot.caption = element_text(size = 8)        # Caption size
  )
```
Describe how, according to the model, the odds of having low plasma β-carotene changes when BMI is
(i) increased by 1 unit,
(ii) decreased by 1 unit,
(iii) decreased by 10 units
Also calculate 95 % confidence intervals for these odds ratios.
```{r}
bmi_sum$coefficients[2]
bhat <- bmi_glm$coefficients[2]
bhat
ci.beta1 <- confint(bmi_glm)
ci.beta1 <- ci.beta1[2,]
#ci.beta1
delta_x <- c(+1,-1,-10)
or = exp(bhat*delta_x)
ci.or <- exp(outer(ci.beta1, delta_x, "*"))

#ci.or
cbind('delta_x' = delta_x,'bhat'=bhat, `OR` = or, t(ci.or)) |> round(digits = 4)


```

## 2(b)
Use both a Wald test and an LR-test to determine if the probability of having low plasma β-carotene changes with BMI in Model.2(a).

Report the null hypothesis H0, the values of the respective test statistics, the asymptotic distributions of the test statistics when H0 is true, the P-values and the conclusions
```{r}
# Wald test
bmi_sum$coefficients

# LR-test
D_diff <- bmi_sum$null.deviance - bmi_sum$deviance
df_diff <- bmi_sum$df.null - bmi_sum$df.residual
chi2_alpha <- qchisq(p = 1 - 0.05, df = df_diff)
Pvalue <- pchisq(q = D_diff, df = df_diff, lower.tail = FALSE)

cbind(D_diff, df_diff, chi2_alpha, Pvalue)
```
Wald test:
p-value bmi = 0.001028734 < 0.05
Reject H0, significant

LR-test
p-value = 0.0002806021

Choose LR-test
Warning: For small and medium size data (n < ∞) you should use a likelihood ratio test instead. n= 315
The Wald test relies heavily on asymptotic normality


## 2(c)
Calculate the leverage values for Model.2(a) and plot them against BMI, adding a horizontal line at 2(p + 1)/n for visual reference.
In the same plot, but in a different colour, add the
leverage values from a simple linear regression with BMI as covariate. 
```{r}
bmi_infl <- influence(bmi_glm)
glimpse(bmi_infl)
bmi_lm <- lm(lowplasma_01 ~ bmi, df)

bmi_pred <- cbind(bmi_pred,
                   #xbeta = predict(bmi_glm),
                   v_logistic = bmi_infl$hat,
                  v_linear = hatvalues(bmi_lm))
glimpse(bmi_pred)

pplus1_bmi <- length(bmi_glm$coefficients)
n <- nobs(bmi_glm)

ggplot(bmi_pred, aes(x = bmi)) +
  geom_point(aes(y=v_logistic, color = "logistic")) +
  geom_point(aes(y=v_linear, color = "linear")) +
  geom_hline(yintercept = c(2*pplus1_bmi/n), linetype = "dashed") +
  scale_color_manual(values = c("logistic" = "red", "linear" = "blue")) +
  labs(
    title = "Leverage of BMI",
    x = "BMI (kg/m²)", 
    y = "Leverage",
    color = "Model"
  ) +
  theme(
    plot.title = element_text(size = 10),        # Title size
    axis.title.x = element_text(size = 9),       # X-axis label size
    axis.title.y = element_text(size = 9),       # Y-axis label size
    axis.text.x = element_text(size = 8),        # X-axis tick values
    axis.text.y = element_text(size = 8),         # Y-axis tick values,        # Y-axis tick values
    plot.caption = element_text(size = 8),        # Caption size
    legend.title = element_text(size = 9),
    legend.text = element_text(size = 8)
  )
```
Comment on, and explain, any interesting differences in how the leverages behave, especially when BMI is large.
Linear Model (blue dots):
- Leverage increases sharply as BMI increases beyond ~35.
- Leverage becomes very high for extreme BMI values (e.g., BMI > 45).
- The leverage curve is U-shaped, with low leverage in the middle and high leverage at the extremes.
Leverage for BMI below 38, behave the same for both models

Logistic Model (red dots):
- Leverage is more stable across the BMI range.
- It rises slightly with BMI, but never spikes the way it does in the linear model.
- Even at extreme BMI values, the logistic model contains the leverage more effectively.
Leverage for logistic now depend both on X and Y and, as
such, are no longer indicators of outliers w.r.t. X. Less sensitive to extremes of X

## 2(d)
Calculate the standardized deviance residuals for Model.2(a) and plot them against BMI, using separate colours for low and high concentrations with aes(..., color = lowplasma_hl).

Add reference lines at ±3, ±2 and 0. Try to explain the systematic behaviour of the residuals.

Identify the observations with residuals outside ±2 and explain why they are large. Hint:identify the observations in the plot in 2a
```{r}
bmi_pred |> mutate(devresid = bmi_infl$dev.res,
                    stddevresid = devresid/sqrt(1 - v_logistic)) -> bmi_pred

ggplot(bmi_pred, aes(x = bmi, 
                      y = stddevresid, 
                      color = as.factor(lowplasma_hl))) +
  geom_point() +
  geom_hline(yintercept = c(-3, -2, 0, 2, 3), 
             linetype = c("dotted", "dashed", "solid", "dashed", "dotted"),
             linewidth = 1) +
  labs(title = "Standardised deviance residuals vs BMI",
       x = "BMI (kg/m²)", y = "devstd",
       color = "Y") +
  theme(
    plot.title = element_text(size = 10),        # Title size
    axis.title.x = element_text(size = 9),       # X-axis label size
    axis.title.y = element_text(size = 9),       # Y-axis label size
    axis.text.x = element_text(size = 8),        # X-axis tick values
    axis.text.y = element_text(size = 8),         # Y-axis tick values,        # Y-axis tick values
    plot.caption = element_text(size = 8),        # Caption size
    legend.title = element_text(size = 9),
    legend.text = element_text(size = 8)
  )

filter(bmi_pred, abs(stddevresid)>2)

ggplot(bmi_pred, aes(bmi, lowplasma_01)) +
  geom_point() +
  geom_smooth(se = FALSE, linetype = "dashed") +
  geom_line(aes(y = phat), color = "red", size = 1) +
  geom_point(data = filter(bmi_pred, abs(stddevresid)>2), 
             aes(color = "|d|>2"), size = 3) +
  geom_ribbon(aes(ymin = p.lwr, ymax = p.upr), alpha = 0.2) +
  xlab("BMI (kg/m²)") +
  ylab("Low betaplasma") +
  labs(title = "Low betaplasma (=1) or Not low betaplasma (=0) vs BMI",
       caption = "red = fitted line, with 95% confidence interval, 
       blue dashed = moving average") + 
  scale_color_manual(values = highlightcolors)+
  theme(legend.position = "bottom",
    plot.title = element_text(size = 10),        # Title size
    axis.title.x = element_text(size = 9),       # X-axis label size
    axis.title.y = element_text(size = 9),       # Y-axis label size
    axis.text.x = element_text(size = 8),        # X-axis tick values
    axis.text.y = element_text(size = 8),         # Y-axis tick values,        # Y-axis tick values
    plot.caption = element_text(size = 8),        # Caption size
    legend.title = element_text(size = 9),
    legend.text = element_text(size = 8)
  )
```
Those outliners due to being against the trend of high BMI, low plasma

## 2(e)
Calculate Cook’s distance for Model.2(a) and plot them against BMI using separate colours for low and high concentrations. Add a suitable reference line as visual guide and highlight the observations with the large residuals from 2(d)
```{r}
bmi_pred <- mutate(bmi_pred, 
                    Dcook = cooks.distance(bmi_glm))
bmi_pred
ggplot(bmi_pred, aes(x = bmi, y = Dcook, 
                      color = as.factor(lowplasma_hl))) +
  geom_point() +
  #geom_point(data = filter(bmi_pred, v_logistic > 0.045), aes(color = "v > 0.045"),
   #          size = 3) +
  #geom_point(data = filter(bmi_pred, Dcook > 0.1), aes(color = "Cook's D>0.1"),
   #          size = 3) +
  #geom_point(data = filter(bmi_pred, abs(stddevresid)>2), 
   #          aes(color = "|d|>2"), size = 3) +
  geom_hline(yintercept = 4/n, linewidth = 1, linetype = "dashed") +
  labs(title = "Cook's distance vs BMI",
       x = "BMI (kg/m²)", 
       color = "Highlight") +
  theme(legend.position = "bottom",
    plot.title = element_text(size = 10),        # Title size
    axis.title.x = element_text(size = 9),       # X-axis label size
    axis.title.y = element_text(size = 9),       # Y-axis label size
    axis.text.x = element_text(size = 8),        # X-axis tick values
    axis.text.y = element_text(size = 8),         # Y-axis tick values,        # Y-axis tick values
    plot.caption = element_text(size = 8),        # Caption size
    legend.title = element_text(size = 9),
    legend.text = element_text(size = 8)
  )
```
Which observation had the largest influence? The second largest?
```{r}
arrange(filter(bmi_pred, abs(stddevresid)>2), Dcook)
# largest D cook = 0.17647045, high betaplasma, bmi=45.9	
# Second largest 0.08332085, bmi=39.5
```
Explain why, with some help from the plot in 2(a).
- Limited data at high bmi
- plot 2A, the number of people with very high BMI is likely low.
- The model is made based on limited data, less reliable predictions and higher residuals

# 3 Multiple logistic regression and model selection
## 3(a)
Fit a multiple logistic model using all 11 x-variables, including calories, and calculate the VIF-values. 

Did the change of model from a linear regression in Projekt 1.3(c) to a logistic regression, affect the VIF? Why not? In all further analyses, exclude the variable with the
multicollinearity issues.

```{r echo=FALSE, warning=FALSE, paged.print=FALSE}
mutate(df,
       sex = factor(sex,
                         levels = c(1, 2),
                         labels = c("male", "female"))) -> df
mutate(df,
       smokstat = factor(smokstat,
                     levels = c(1, 2, 3),
                     labels = c("never", "former", "current"))) -> df

glimpse(df)
df <- mutate(df, smokstat = relevel(smokstat, "never"), 
             sex = relevel(sex, "female"))
all_glm <- glm(lowplasma_01 ~ bmi + age + calories + fat + cholesterol + fiber + alcohol + betadiet + smokstat + sex + vituse, family = "binomial", data = df)
vif(all_glm)
summary(all_glm)
```
Lecture 4
VIF_j = 1/(1-R^2_j)
R_j = Corr(X.j, Xhat_j)
The square of the correlation, 0 ≤ R2 j ≤ 1, is the amount of variability in covariate xj that can be explained by the other x-variables, see Lecture 6
VIF does not depend on the outcome variable
So, VIF values will be identical whether you're using: Linear regression or Logistic regression

calories will be excluded
```{r}
excl_glm <- glm(lowplasma_01 ~ (bmi + age + fat + cholesterol + fiber + alcohol + betadiet + smokstat + sex + vituse)^2, family = "binomial", data = df)
excl_glm
```
Perform one Backwards elimination, starting with the full model, and one Forward selection, starting with the null model. Both versions should have the null model as lower scope and the full model as upper scope, and use BIC as selection criterion.
```{r warning=FALSE, include=FALSE, paged.print=FALSE}
excl_sum <- summary(excl_glm)
#excl_sum
null_glm <- glm(lowplasma_01 ~ 1, family = "binomial", data = df)
backward_model <- step(excl_glm, 
     scope = list(lower = null_glm, upper = excl_glm),
     direction = "backward",
     k = log(nobs(excl_glm)))
#backward_model <- step(excl_glm, direction = "backward", k = log(nobs(excl_glm)))
# AIC unless we supply k=log(n)

```
Then, use each of the resulting models as starting model in a Stepwise regression, again with null and full models as scope, and BIC as criterion
```{r message=FALSE, warning=FALSE, include=FALSE}
# BIC since we supplied k=log(n)

backward_stepwise_model <- step(backward_model, 
     scope = list(lower = null_glm, upper = excl_glm),
     direction = "both",
     k = log(nobs(excl_glm)))
backward_stepwise_model
```

```{r include=FALSE}
forward_model <- step(null_glm,
     k = log(nobs(excl_glm)),
     scope = list(lower = null_glm, upper = excl_glm),, 
     direction = "forward")
forward_model
```


```{r message=FALSE, warning=FALSE, include=FALSE}

forward_stepwise_model <- step(forward_model, 
     scope = list(lower = null_glm, upper = excl_glm),
     direction = "both",
     k = log(nobs(excl_glm)))
```

    
```{r}
forward_stepwise_model
BIC(excl_glm, backward_model, backward_stepwise_model, forward_model, forward_stepwise_model)
```



If any of the resulting Stepwise models contain categorical variables, determine, using a suitable test, if you can reduce the number of categories from three to two in any of those variables.

If so, fit the reduced model version as well and report the details of the test comparing the reduced model with two categories, with the larger model with three categories.
Report the name of the test, the null hypothesis, the value of the test statistic, its distribution when H0 is true, the P-value and the conclusion.
```{r}
backward_stepwise_sum <- summary(backward_stepwise_model)
backward_stepwise_sum

#glimpse(df)

forward_stepwise_sum <- summary(forward_stepwise_model)
forward_stepwise_sum

forward_stepwise_sum$coefficients
bhat <- forward_stepwise_model$coefficients
ci.beta <- confint(forward_stepwise_model)
or = exp(bhat)
ci.or <- exp(ci.beta)

cbind('beta'=bhat,ci.beta) |> round(digits = 4)
```

```{r}
glimpse(df)
mutate(df, 
       vituse_new = factor(vituse == "no",
                         levels = c(FALSE, TRUE),
                         labels = c("yes", "no"))) -> df
glimpse(df)
count(df, vituse_new)
# not vituseoften = often + notoften as reference
df <- mutate(df, vituse_new = relevel(vituse_new, "yes"))
forward_stepwise_new <- glm(formula = lowplasma_01 ~ betadiet + bmi + vituse_new + age + 
    betadiet:bmi, family = "binomial", data = df)
forward_stepwise_new_sum <- summary(forward_stepwise_new)
forward_stepwise_new_sum
```

LR test
```{r}
D_diff <- forward_stepwise_new_sum$deviance - forward_stepwise_sum$deviance
df_diff <- forward_stepwise_new_sum$df.residual - forward_stepwise_sum$df.residual
cbind(D_diff, df_diff)

chi2_alpha <- qchisq(1 - 0.05, df_diff)
Pvalue <- pchisq(D_diff, df_diff, lower.tail = FALSE)
cbind(D_diff, df_diff, chi2_alpha, Pvalue)
forward_stepwise_new_sum$deviance
```

```{r}
anova_stepwise <- anova(forward_stepwise_new, forward_stepwise_model)
anova_stepwise
```

vitusenotoften not significant


Present a table, Table.3(b), with the estimated β-parameters in each of the different models (you will end up with at least one and at most six different models). Use one row for each variable that is present in at least one of the models, and one column of estimates for each of the models
```{r}

df1 <- data.frame(variable = names(null_glm$coefficients),
b_model1 = null_glm$coefficients, row.names = NULL)


df2 <- data.frame(variable = names(excl_glm$coefficients),
b_full = excl_glm$coefficients, row.names = NULL)

df3 <- data.frame(variable = names(backward_model$coefficients),
b_backward = backward_model$coefficients, row.names = NULL)

df4 <- data.frame(variable = names(backward_stepwise_model$coefficients),
b_backstep = backward_stepwise_model$coefficients, row.names = NULL)

df5 <- data.frame(variable = names(forward_model$coefficients),
b_forward = forward_model$coefficients, row.names = NULL)

df6 <- data.frame(variable = names(forward_stepwise_model$coefficients),
b_model6 = forward_stepwise_model$coefficients, row.names = NULL)

df7 <- data.frame(variable = names(forward_stepwise_new$coefficients),
b_redmodel = forward_stepwise_new$coefficients, row.names = NULL)

models <- full_join(df3,df4) |> full_join(df5) |> full_join(df7)
print(models)
```


## 3(c)
Calculate McFadden’s adjusted pseudo R2, AIC and BIC for all models from Table.3(b), and indicate which model is best, according to each of these criteria

```{r}
aic <- AIC(backward_model, backward_stepwise_model, forward_model, forward_stepwise_new)
bic <- BIC(backward_model, backward_stepwise_model, forward_model, forward_stepwise_new)
collect.AICetc <- data.frame(aic, bic)
collect.AICetc
```

```{r}

collect.AICetc |> mutate(df.1 = NULL) -> collect.AICetc
collect.AICetc

logLik(null_glm)
lnL0 <- logLik(null_glm)[1]
lnL0

collect.AICetc |> mutate(
  loglik =  c(logLik(backward_model)[1],
              logLik(backward_stepwise_model)[1],
              logLik(forward_model)[1],
              logLik(forward_stepwise_new)[1])) -> collect.AICetc
collect.AICetc

collect.AICetc |> mutate(
  #R2McF = 1 - loglik/lnL0,
  R2McF.adj = 1 - (loglik - (df - 1)/2)/lnL0) -> collect.AICetc
collect.AICetc


```
Best
AIC: BACKward_stepwise_model
BIC: forward_stepwise_model
R2McF.adj: excl_glm


## 3(d)
Calculate the standardised deviance residuals for the model with the best AIC and the model with the best BIC, from 3(c). 
Plot the standardised deviance residuals, with suitable reference lines, against the linear predictors for each of the two models. 

Also make QQ-plots for the residuals. Discuss which of the models has the best behaved residuals

```{r}
bestmodelaic_infl <- influence(backward_stepwise_model)
glimpse(bestmodelaic_infl)

bestmodelaic_pred <- cbind(df,
                   xbeta = predict(backward_stepwise_model),
                   v = bestmodelaic_infl$hat)
glimpse(bestmodelaic_pred)

bestmodelaic_pred |> mutate(devresid = bestmodelaic_infl$dev.res,
                    stddevresid = devresid/sqrt(1 - v)) -> bestmodelaic_pred
glimpse(bestmodelaic_pred)

pplus1_bestmodelaic <- length(backward_stepwise_model$coefficients)
n <- nobs(backward_stepwise_model)

bestmodelaic_pred |> mutate(pearson = bestmodelaic_infl$pear.res,
                    stdpearson = pearson/sqrt(1 - v)) -> bestmodelaic_pred
glimpse(bestmodelaic_pred)

ggplot(bestmodelaic_pred, aes(x = xbeta, 
                      y = stddevresid, 
                      color = as.factor(lowplasma_hl))) +
  geom_point() +
  geom_hline(yintercept = c(-3, -2, 0, 2, 3), 
             linetype = c("dotted", "dashed", "solid", "dashed", "dotted"),
             linewidth = 1) +
  labs(title = "Standardised deviance residuals vs linear predictor (Best AIC model)",
       x = "xb", y = "devstd",
       color = "Y") +
  theme(
    plot.title = element_text(size = 10),        
    axis.title.x = element_text(size = 9),       
    axis.title.y = element_text(size = 9),       
    axis.text.x = element_text(size = 8),        
    axis.text.y = element_text(size = 8),        
    legend.text = element_text(size = 8),        # Legend label size
    legend.title = element_text(size = 9)        # Legend title size
  )
```
```{r warning=FALSE}
bestmodelbic_infl <- influence(forward_stepwise_new)
glimpse(bestmodelbic_infl)

bestmodelbic_pred <- cbind(df,
                   xbeta = predict(forward_stepwise_new),
                   v = bestmodelbic_infl$hat)
glimpse(bestmodelbic_pred)

bestmodelbic_pred |> mutate(devresid = bestmodelbic_infl$dev.res,
                    stddevresid = devresid/sqrt(1 - v)) -> bestmodelbic_pred
glimpse(bestmodelbic_pred)

pplus1_bestmodelbic <- length(forward_stepwise_new$coefficients)
n <- nobs(forward_stepwise_new)

bestmodelbic_pred |> mutate(pearson = bestmodelbic_infl$pear.res,
                    stdpearson = pearson/sqrt(1 - v)) -> bestmodelbic_pred
glimpse(bestmodelbic_pred)

ggplot(bestmodelbic_pred, aes(x = xbeta, 
                      y = stddevresid, 
                      color = as.factor(lowplasma_hl))) +
  geom_point() +
  geom_hline(yintercept = c(-3, -2, 0, 2, 3), 
             linetype = c("dotted", "dashed", "solid", "dashed", "dotted"),
             linewidth = 1) +
  labs(title = "Standardised deviance residuals vs linear predictor (Best BIC model)",
       x = "xb", y = "devstd",
       color = "Y") +
  theme(
    plot.title = element_text(size = 10),        
    axis.title.x = element_text(size = 9),       
    axis.title.y = element_text(size = 9),       
    axis.text.x = element_text(size = 8),        
    axis.text.y = element_text(size = 8),        
    legend.text = element_text(size = 8),        # Legend label size
    legend.title = element_text(size = 9)        # Legend title size
  )
sum(abs(bestmodelaic_pred$stddevresid) > 2)

sum(abs(bestmodelbic_pred$stddevresid) > 2)
```

```{r}
ggplot(bestmodelaic_pred, aes(sample = stdpearson)) +
  geom_qq() + geom_qq_line() +
  labs(title = "Q-Q-plot standardised residuals (best AIC model)",
       x = "theoretical", y = "sample")  +
  theme(
    plot.title = element_text(size = 10),        
    axis.title.x = element_text(size = 9),       
    axis.title.y = element_text(size = 9),       
    axis.text.x = element_text(size = 8),        
    axis.text.y = element_text(size = 8),        
    legend.text = element_text(size = 8),        # Legend label size
    legend.title = element_text(size = 9)        # Legend title size
  )

ggplot(bestmodelbic_pred, aes(sample = stdpearson)) +
  geom_qq() + geom_qq_line() +
  labs(title = "Q-Q-plot standardised residuals (best BIC model)",
       x = "theoretical", y = "sample") +
  theme(
    plot.title = element_text(size = 10),        
    axis.title.x = element_text(size = 9),       
    axis.title.y = element_text(size = 9),       
    axis.text.x = element_text(size = 8),        
    axis.text.y = element_text(size = 8),        
    legend.text = element_text(size = 8),        # Legend label size
    legend.title = element_text(size = 9)        # Legend title size
  )

sum(abs(bestmodelaic_pred$stdpearson) > 2)

sum(abs(bestmodelbic_pred$stdpearson) > 2)
```

# 4. Goodness-of-fit
We will now compare the two models from 3(d), and their ability to predict whether the plasma β-carotene concentration is low or not.

# 4(a)
Start by using the cut-off value 0.5, classifying observations with ˆpi ≤ 0.5 as ”should not have low concentration”, and observations with ˆpi > 0.5 as ”should have low concentration".

Present the resulting confusion matrices as well as a table, Table 4(a), collecting the Accuracy, the P-value for Acc > NIR, Cohen’s κ, the P-value for McNemar’s test, the Sensitivity and the Specificity for each of the two models.

```{r}
df |> mutate(
  p_AIC = predict(backward_stepwise_model, type = "response"),
  p_BIC = predict(forward_stepwise_new, type = "response")
) -> pred_phat
glimpse(pred_phat)

pred_phat |> mutate(
  yhat_AIC = factor(p_AIC > 0.5,
                     levels = c(FALSE, TRUE),
                     labels = c("high", "low"))) -> pred_phat

pred_phat |> mutate(
  yhat_BIC = factor(p_BIC > 0.5,
                     levels = c(FALSE, TRUE),
                     labels = c("high", "low"))) -> pred_phat
#view(pred_phat)
cm_AIC <- confusionMatrix(
  data = pred_phat$yhat_AIC, 
  reference = pred_phat$lowplasma_hl,
  positive = "low")
cm_AIC

cm_BIC <- confusionMatrix(
  data = pred_phat$yhat_BIC, 
  reference = pred_phat$lowplasma_hl,
  positive = "low")
cm_BIC
```
# 4(b) Plot the ROC-curves for both models in the same plot, present a table with their AUC-values, including 95 % confidence intervals, and perform a pair-wise test comparing their
AUC-values and discuss the result.

```{r}
roc_AIC <- roc(lowplasma_01 ~ p_AIC, data = pred_phat)
roc_AIC

coords(roc_AIC) |> head()

roc_BIC <- roc(lowplasma_01 ~ p_BIC, data = pred_phat)
roc_BIC

coords(roc_BIC) |> head()

ggroc(list(AIC = roc_AIC, BIC = roc_BIC)) +
  coord_fixed() +
  labs(title = "ROC-curves for model AIC and the BIC model") +
  theme(
    plot.title = element_text(size = 10),        
    axis.title.x = element_text(size = 9),       
    axis.title.y = element_text(size = 9),       
    axis.text.x = element_text(size = 8),        
    axis.text.y = element_text(size = 8),        
    legend.text = element_text(size = 8),        # Legend label size
    legend.title = element_text(size = 9)        # Legend title size
  )
```
```{r}
aucs <- 
  data.frame(
    model = c("AIC", "BIC"),
    auc = c(auc(roc_AIC), auc(roc_BIC)),
    lwr = c(ci(roc_AIC)[1], ci(roc_BIC)[1]),
    upr = c(ci(auc(roc_AIC))[3], ci(auc(roc_BIC))[3]))
aucs
```
```{r}
roc.test(roc_AIC, roc_BIC)
```
# 4(c) 
For each of the two models, find the optimal threshold for p, where the distance to the ideal model is minimized. Use these new thresholds to calculate new confusion matrices and a
new version of Table.4(a), with the optimal thresholds added, Table.4(c).

Comment on any interesting differences between the conclusions that can be drawn from the two 
```{r}
topleft_AIC <- coords(roc_AIC, "best", best.method = "closest.topleft")
topleft_AIC
topleft_AIC$threshold
topleft_BIC <- coords(roc_BIC, "best", best.method = "closest.topleft")
topleft_BIC

```
```{r}


pred_phat |> mutate(
  yhat_new_AIC = factor(p_AIC > topleft_AIC$threshold,
                     levels = c(FALSE, TRUE),
                     labels = c("high", "low"))) -> pred_phat

pred_phat |> mutate(
  yhat_new_BIC = factor(p_BIC > topleft_BIC$threshold,
                     levels = c(FALSE, TRUE),
                     labels = c("high", "low"))) -> pred_phat

#view(pred_phat)
cm_new_AIC <- confusionMatrix(
  data = pred_phat$yhat_new_AIC, 
  reference = pred_phat$lowplasma_hl,
  positive = "low")
cm_new_AIC

cm_new_BIC <- confusionMatrix(
  data = pred_phat$yhat_new_BIC, 
  reference = pred_phat$lowplasma_hl,
  positive = "low")
cm_new_BIC
```
# 4(d). 
Taking all the results into account, select the model you would prefer as the overall “best” model. Describe the reasons behind your decision

Present the best model, the eβ -estimates and their corresponding 95 % confidence intervals.

Comment on the variables and the possible reasons for why they would have that positive/negative effect on the probability of having a low plasma β-carotene concentration
```{r}
exp(forward_stepwise_new$coefficients)
exp(confint(forward_stepwise_new))

```

